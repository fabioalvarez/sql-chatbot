from dotenv import load_dotenv
from sqlalchemy import Engine
from db import init_db_engine
from vector_db import initialize_vector_db
from prompts import prompts
from text_to_sql import LlmResponseParser, TableContextCreator

from llama_index.llms.openai import OpenAI
from llama_index.core.objects import ObjectRetriever
from llama_index.core.query_pipeline import FnComponent
from llama_index.core.indices.struct_store.sql_retriever import SQLRetriever
from llama_index.core import SQLDatabase, PromptTemplate

from llama_index.core.query_pipeline import (
    QueryPipeline as Qp,
    InputComponent, QueryPipeline,
)


def init_text_to_sql() -> (Engine, SQLDatabase, OpenAI, ObjectRetriever, FnComponent):
    """
    Initializes the components required for the Text-to-SQL application.

    Returns:
        tuple: A tuple containing the following elements:
            - engine (Engine): The SQLAlchemy engine object.
            - db (SQLDatabase): The SQL database object.
            - llm (OpenAI): The language model object.
            - obj_retriever (ObjectRetriever): The object retriever component for the vector database.
            - context_creator_component (FnComponent): The context creator component for the vector database.
    """
    # Load environment variables from a .env file
    load_dotenv()

    # Create the SQL engine and initialize SQL database
    engine = init_db_engine()
    db = SQLDatabase(engine)

    # Initialize the language model
    llm = OpenAI(model="gpt-3.5-turbo")

    # Initialize vector DB
    obj_retriever = initialize_vector_db(llm, engine, db)

    # Creates full context for relevant tables
    context_creator = TableContextCreator(db)
    context_creator_component = context_creator.get_component()

    return engine, db, llm, obj_retriever, context_creator_component


def orchestrator(
        llm,
        db,
        obj_retriever,
        context_creator,
        dialect: str,
        question: str,
        verbose: bool = False,
) -> str:
    """
    Orchestrates the process of generating and executing an SQL query from a natural language question.

    Args:
        llm (OpenAI): The language model used for generating SQL queries and responses.
        db (SQLDatabase): The SQL database object used for retrieving table information.
        obj_retriever (ObjectRetriever): The component responsible for retrieving relevant objects from the vector
        store.
        context_creator (FnComponent): The component responsible for creating context strings for tables.
        dialect (str): The SQL dialect to be used (e.g., 'mysql', 'postgresql').
        question (str): The natural language question to be converted into an SQL query.
        verbose (bool): Whether to print verbose output during the orchestration process.

    Returns:
        str: The final response generated by the language model.

    Raises:
        Exception: If any error occurs during the orchestration process, the exception is caught and its message is
        returned.
    """
    try:
        # Text to SQL prompt. This is the prompt that the model will use to generate the SQL query
        text2sql_prompt_str = PromptTemplate(prompts.text_to_sql)
        text2sql_prompt = text2sql_prompt_str.partial_format(dialect=dialect)

        # Parse response to SQL query
        response_parser = LlmResponseParser()
        sql_parser_component = response_parser.parse_sql_component()

        # Prepare the response synthesis prompt
        question_synthesis_prompt = PromptTemplate(prompts.question_synthesis)

        # Create and configure the query pipeline
        qp = Qp(
            verbose=verbose,
            modules={
                "input": InputComponent(),
                "obj_retriever": obj_retriever,
                "context_creator_component": context_creator,
                "text2sql_prompt": text2sql_prompt,
                "text2sql_llm": llm,
                "sql_output_parser": sql_parser_component,
                "sql_retriever": SQLRetriever(db),
                "question_synthesis_prompt": question_synthesis_prompt,
                "response_synthesis_llm": llm,
            },
        )

        # Orchestrate the pipeline
        qp = pipeline_orchestrator(qp)

        response, intermediates = qp.run_with_intermediates(question=question)
        return extract_response(str(response))

    except Exception as e:
        return str(e)


def pipeline_orchestrator(qp) -> QueryPipeline:
    """
    Configures and orchestrates the query pipeline.

    This function sets up the query pipeline by adding chains and links between various components.
    It defines the flow of data through the pipeline, specifying how the input is processed and how
    the components interact to generate the final response.

    Args:
        qp (QueryPipeline): The query pipeline object to be configured.

    Returns:
        QueryPipeline: The configured query pipeline object.
    """
    qp.add_chain(["input", "obj_retriever", "context_creator_component"])

    qp.add_link("input", "text2sql_prompt", dest_key="question")
    qp.add_link("context_creator_component", "text2sql_prompt", dest_key="schema")

    qp.add_chain(["text2sql_prompt", "text2sql_llm", "sql_output_parser", "sql_retriever"])

    qp.add_link("sql_output_parser", "question_synthesis_prompt", dest_key="sql_query")
    qp.add_link("sql_retriever", "question_synthesis_prompt", dest_key="context_str")
    qp.add_link("input", "question_synthesis_prompt", dest_key="question")

    qp.add_link("question_synthesis_prompt", "response_synthesis_llm")

    return qp


def extract_response(text: str) -> str:
    """
    Extracts the text following the keyword "assistant:" from the given string.

    This function searches for the keyword "assistant:" in the input text and returns the text that follows it.
    If the keyword is not found, it returns an empty string.

    Args:
        text (str): The input string from which to extract the text.

    Returns:
        str: The extracted text following the keyword "assistant:", or an empty string if the keyword is not found.
    """
    keyword = "assistant:"
    start_index = text.find(keyword)
    if start_index != -1:
        return text[start_index + len(keyword):].strip()
    return ""
